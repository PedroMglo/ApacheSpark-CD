{
  "name": "pyspark-dev",
  "dockerComposeFile": "docker-compose.yml",
  "service": "app",
  "runServices": ["db"],
  "workspaceFolder": "/workspaces/ApacheSpark-CD",
  "remoteUser": "vscode",

  "customizations": {
    "vscode": {
      "extensions": [
        "ms-python.python",
        "ms-toolsai.jupyter",
        "mtxr.sqltools",
        "mtxr.sqltools-driver-pg"
      ],
      "settings": {
        "python.defaultInterpreterPath": "/workspaces/ApacheSpark-CD/.venv/bin/python"
      }
    }
  },

  "containerEnv": {
    "JAVA_OPTS": "-Xms512m -Xmx4g",
    "_JAVA_OPTIONS": "-Xms512m -Xmx4g",
    "POSTGRES_USER": "postgres",
    "POSTGRES_PASSWORD": "postgres_password",
    
    // MUDANÇA CRUCIAL: Agora apontamos para o nome do serviço no Docker Compose
    "POSTGRES_HOST": "db" 
  },

  "remoteEnv": {
    "VIRTUAL_ENV": "/workspaces/ApacheSpark-CD/.venv",
    "PYSPARK_PYTHON": "/workspaces/ApacheSpark-CD/.venv/bin/python",
    "PYSPARK_DRIVER_PYTHON": "/workspaces/ApacheSpark-CD/.venv/bin/python"
  },

  "postCreateCommand": "bash .devcontainer/bootstrap.sh && bash scripts/get_data.sh",
  "postStartCommand": "bash .devcontainer/run_all_sql_files.sh",

  "features": {
    "ghcr.io/devcontainers/features/java:1": {
      "version": "17"
    }
  }
}