## 0.2. Arquitetura (Driver, Executors, Cluster Manager)

Spark é um sistema **master/worker** lógico. Os termos principais:

- **Driver**: “cérebro” do job Spark.
- **Executors**: “músculo” – processos que executam as tasks.
- **Cluster Manager**: componente que gere recursos do cluster.

### Visão geral de alto nível

Quando corres um programa em PySpark:

1. O teu código Python é o **programa do driver**.
2. Esse driver:
   - Fala com o **Cluster Manager** para pedir recursos (executors).
   - Constrói o **plano lógico** das operações (DAG de transformações).
   - O Catalyst converte em **plano físico** (estratégias de execução).
3. O **Cluster Manager** inicia **executors** nas máquinas do cluster.
4. O driver envia **tasks** para os executors.
5. Os executors:
   - Lêem dados, executam transformações, fazem shuffle, escrevem resultados.
   - Comunicam progresso e métricas ao driver.

Vamos por partes.

---

### 0.2.1. Driver

O **Driver** é um processo (JVM) onde corre:

- A **SparkSession**.
- O **código que constrói o plano lógico** (quando fazes `.select`, `.join`, `.groupBy`, etc.).
- O **Catalyst Optimizer** (plano lógico → plano físico).
- O **Scheduler**:
  - Divide o job em **stages**.
  - Dentro de cada stage, cria **tasks** (uma por partição).
  - Distribui tasks pelos executors.
- A lógica de **coordenação**:
  - Re-executar tasks falhadas.
  - Decidir estratégias (com AQE ativado).
  - Orquestrar o fluxo global do job.

No contexto de PySpark:

- O driver tem:
  - Processo Python (onde escreves o código).
  - Processo JVM (Spark context real).
- Há uma **ponte** entre Python ↔ JVM:
  - Define DataFrames em Python → converte para um plano em JVM.
  - Certas operações (UDFs Python) implicam data ser deserializada para Python nos executors.

**Pontos técnicos importantes**:

- Se o driver morrer a meio do job, **o job termina** (os executors param).
- O driver é o “single point of coordination”.
- Em streaming, o driver também é o responsável por manter a “query” viva.

---

### 0.2.2. Executors

Os **Executors** são processos que correm nas máquinas de worker do cluster.

- Criados pelo **Cluster Manager** a pedido do driver.
- Cada executor tem:
  - **Heap de memória** dedicada (`spark.executor.memory`).
  - **CPU cores** (`spark.executor.cores`).
  - Espaço temporário para spill em disco.
  - Threads que executam as **tasks**.

Responsabilidades dos executors:

- Executar tasks (map, filter, join, aggregation, etc.).
- Manter dados em cache/persistência (quando fazes `df.cache()`).
- Fazer shuffle (ler e escrever dados de/para outros executors).
- Enviar métricas / progresso para o driver.

**Relação executors vs tasks**:

- Cada executor pode correr **várias tasks em paralelo**, limitado pelos cores atribuídos:
  - Ex.: `spark.executor.cores = 4` → até 4 tasks em paralelo por executor.
- Cada task trata de **uma partição** de dados.

---

### 0.2.3. Cluster Manager

O **Cluster Manager** gere **recursos físicos** (máquinas, CPUs, memória) e aloca executors.

Principais opções:

- **Standalone**: cluster manager nativo do Spark.
- **YARN** (Hadoop):
  - Bastante usado em clusters on-prem ou cloud compatível com Hadoop.
- **Kubernetes**:
  - Cada executor como um pod.
- (Menos comum hoje) **Mesos**.

O que o Cluster Manager faz:

- Recebe pedido do driver: “preciso de X executors com Y memória e Z cores”.
- Encontra máquinas com recursos suficientes.
- Lança processos executors.
- Monitoriza executors (se um executor cai, o cluster manager informa o driver, que replaneia tasks).

---

### 0.2.4. Fluxo simplificado de um job

1. Lançar a aplicação Spark:
   - Podes usar `spark-submit` ou Spark via notebook / IDE.
2. O driver pede executors ao Cluster Manager.
3. Os executors iniciam-se nas máquinas físicas.
4. O driver constrói o DAG (plano lógico).
5. Ao chamar uma **ação** (`count`, `show`, `collect`, `write`), o driver:
   - Gera o plano físico.
   - Divide em stages.
   - Cria tasks por partição.
6. Tasks são enviadas para executors.
7. Executors executam, devolvem resultados ou escrevem para o destino.
8. Quando o job termina, executors são libertados (dependendo do modo).
