## 0.4. Primeira `SparkSession` (configs essenciais)

### 0.4.1. SparkSession

Em Spark moderno, tudo começa com a `SparkSession`:

```python
from pyspark.sql import SparkSession

spark = (
    SparkSession.builder
    .appName("exemplo-fundamentos")
    .master("local[*]")  # em cluster, normalmente não se especifica o master aqui
    .config("spark.sql.shuffle.partitions", "200")
    .config("spark.sql.adaptive.enabled", "true")  # AQE
    .getOrCreate()
)
```

Configs essenciais a ter atenção (a ajustar conforme o contexto):

- `spark.sql.shuffle.partitions`
  - Nº de partitions de shuffle default (usado em joins, groupBy, etc.).
- `spark.sql.adaptive.enabled`
  - Ativar Adaptive Query Execution (recomendado).
- `spark.executor.memory`, `spark.executor.cores`, `spark.executor.instances`
  - Mais usados em `spark-submit` (em cluster), não tanto em código.
- `spark.driver.memory`
  - Tamanho de memória do driver (relevante se usares muitas ações que trazem dados para o driver).

Para desenvolvimento local:

- `master("local[*]")`:
  - Corre o driver e executors (lógicos) na tua máquina.
  - `[*]` usa todos os cores disponíveis.

---

## 0.5. Estrutura de um job Spark (lifecycle)

### 0.5.1. Passos típicos de um job batch

1. **Criar a SparkSession**.
2. **Ler dados** (DataFrames).
3. **Aplicar transformações** (lazy).
4. **Acionar uma ação** (escrita, count, etc.).
5. **Fechar recursos** (opcional em notebooks, essencial em scripts).

Exemplo:

```python
from pyspark.sql import SparkSession
from pyspark.sql import functions as F

spark = (
    SparkSession.builder
    .appName("job-exemplo")
    .getOrCreate()
)

# 1. Leitura
df = (
    spark.read
    .option("header", "true")
    .option("inferSchema", "true")
    .csv("/path/dados.csv")
)

# 2. Transformações (apenas constroem o DAG)
df_filtrado = df.filter(F.col("ativo") == True)
df_agregado = df_filtrado.groupBy("categoria").agg(F.sum("valor").alias("total_valor"))

# 3. Ação (escrita) – aqui o job é realmente executado
(
    df_agregado
    .write
    .mode("overwrite")
    .parquet("/path/output")
)

spark.stop()
```

### 0.5.2. O que acontece internamente neste lifecycle

1. **Durante as transformações**:
   - O driver constrói o DAG lógico.
   - Nada é executado nos executors ainda.
2. **Quando chamas `.write.parquet`**:
   - Spark desencadeia um job.
   - Otimiza o plano lógico (Catalyst).
   - Determina os stages (por ex.:
     - Stage 1: leitura + filter + project.
     - Stage 2: shuffle (groupBy) + write).
   - Determina o número de tasks:
     - Stage 1: número de输入 partitions.
     - Stage 2: número de shuffle partitions.
   - Envia tasks para executors.
3. **Durante a execução**:
   - Executors:
     - Lêem os ficheiros.
     - Processam as partitions.
     - Fazem shuffle quando necessário.
     - Escrevem ficheiros de saída em paralelo.
   - O driver monitoriza:
     - Métricas de cada task.
     - Falhas para reexecução, se necessário.
4. **Fim**:
   - Se tudo corre bem, o job termina com sucesso.
   - Spark liberta recursos (executors).
   - Chamar `spark.stop()` termina o processo do driver e liberta conexões com o Cluster Manager.

---

### Checklist mental (para tuning e debugging)

- **Driver**:
  - Está a ficar sem memória? (`OutOfMemoryError` no driver).
  - Estás a usar demasiados `collect()` / `toPandas()`?
- **Executors**:
  - Têm memória suficiente?
  - Quantas tasks estão a correr em paralelo?
  - Há muito spill para disco?
- **Partitions**:
  - Quantas partitions no input?
  - `spark.sql.shuffle.partitions` está adequado?
  - Usaste `repartition` ou `coalesce` em pontos estratégicos?
- **Jobs / Stages / Tasks**:
  - Quantos stages o teu job tem?
  - Onde estão os shuffles?
  - Há stages com tasks muito desbalanceadas (skew)?
- **Reexecução de tasks**:
  - Há muitas tasks com falha/retries?
  - A causa é lógica (ex: UDF a lançar exceção) ou infra (OOM, timeout, rede)?

---

Este capítulo dá-te a base para, nos seguintes, entrares em:

- Transformações e ações (lazy evaluation) de forma consciente.
- Leitura de planos (`explain`) e Spark UI.
- Tuning de partitions, joins e execução com base numa compreensão sólida de:
  - Driver
  - Executors
  - Cluster Manager
  - Jobs / Stages / Tasks / DAG
